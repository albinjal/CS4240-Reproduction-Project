{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2U0NA9HrrZey"
   },
   "source": [
    "# Taming Transformers\n",
    "\n",
    "This notebook is a minimal working example to generate landscape images as in [Taming Transformers for High-Resolution Image Synthesis](https://github.com/CompVis/taming-transformers). **tl;dr** We combine the efficiancy of convolutional approaches with the expressivity of transformers by introducing a convolutional VQGAN, which learns a codebook of context-rich visual parts, whose composition is modeled with an autoregressive transformer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4hdc6YonrvoC"
   },
   "source": [
    "## Setup\n",
    "The setup code in this section was written to be [run in a Colab environment](https://colab.research.google.com/github/CompVis/taming-transformers/blob/master/scripts/taming-transformers.ipynb). For a full, local setup, we recommend the provided [conda environment](https://github.com/CompVis/taming-transformers/blob/master/environment.yaml), as [described in the readme](https://github.com/CompVis/taming-transformers#requirements). This will also allow you to run a streamlit based demo.\n",
    "\n",
    "Here, we first clone the repository and download a model checkpoint and config."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eeBqWgMQDjZb"
   },
   "source": [
    "Next, we install minimal required dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hzQNmIuT_0uF",
    "outputId": "e6e1ce0f-bce9-4ebe-a852-95003ca7b630"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: 2.0.0 not found\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install omegaconf>=2.0.0 pytorch-lightning>=1.0.8 einops transformers\n",
    "import sys\n",
    "sys.path.append(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5gaAQZXTxFxD"
   },
   "source": [
    "## Loading the model\n",
    "\n",
    "We load and print the config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hUOUJaTj02Bq",
    "outputId": "6671562d-f7f6-4407-ee40-22e1b83421e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:\n",
      "  params:\n",
      "    batch_size: 30\n",
      "    num_workers: 4\n",
      "    train:\n",
      "      params:\n",
      "        size: 208\n",
      "        training_images_list_file: 1_train.txt\n",
      "      target: taming.data.custom.CustomTrain\n",
      "    validation:\n",
      "      params:\n",
      "        size: 208\n",
      "        test_images_list_file: 1_test.txt\n",
      "      target: taming.data.custom.CustomTest\n",
      "  target: main.DataModuleFromConfig\n",
      "model:\n",
      "  base_learning_rate: 4.5e-06\n",
      "  params:\n",
      "    cond_stage_config: __is_unconditional__\n",
      "    first_stage_config:\n",
      "      params:\n",
      "        ckpt_path: logs/2023-03-30T13-19-11_custom_vqgan/checkpoints/last.ckpt\n",
      "        ddconfig:\n",
      "          attn_resolutions:\n",
      "          - 16\n",
      "          ch: 128\n",
      "          ch_mult:\n",
      "          - 1\n",
      "          - 1\n",
      "          - 2\n",
      "          - 2\n",
      "          - 4\n",
      "          double_z: false\n",
      "          dropout: 0.0\n",
      "          in_channels: 3\n",
      "          num_res_blocks: 2\n",
      "          out_ch: 3\n",
      "          resolution: 256\n",
      "          z_channels: 256\n",
      "        embed_dim: 256\n",
      "        lossconfig:\n",
      "          target: taming.modules.losses.vqperceptual.DummyLoss\n",
      "        n_embed: 1024\n",
      "      target: taming.models.vqgan.VQModel\n",
      "    transformer_config:\n",
      "      params:\n",
      "        block_size: 256\n",
      "        n_embd: 832\n",
      "        n_head: 16\n",
      "        n_layer: 12\n",
      "        vocab_size: 1024\n",
      "      target: taming.modules.transformer.mingpt.GPT\n",
      "  target: taming.models.cond_transformer.Net2NetTransformer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "config_path = \"configs/custom_transformer.yaml\"\n",
    "config = OmegaConf.load(config_path)\n",
    "import yaml\n",
    "print(yaml.dump(OmegaConf.to_container(config)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FzQqNgiLEJ9J"
   },
   "source": [
    "Instantiate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sWvDDVoz3RB4",
    "outputId": "08462e1d-77da-4f9d-d3e9-43bdd2be74b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
      "Restored from logs/2023-03-30T13-19-11_custom_vqgan/checkpoints/last.ckpt\n",
      "Using no cond stage. Assuming the training is intended to be unconditional. Prepending 0 as a sos token.\n"
     ]
    }
   ],
   "source": [
    "from taming.models.cond_transformer import Net2NetTransformer\n",
    "model = Net2NetTransformer(**config.model.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "njAiY_aqENwV"
   },
   "source": [
    "Load the checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "QABLRpVsDhba"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "ckpt_path = \"logs/2023-04-01T12-32-22_custom_transformer/checkpoints/last.ckpt\"\n",
    "sd = torch.load(ckpt_path, map_location=\"cpu\")[\"state_dict\"]\n",
    "missing, unexpected = model.load_state_dict(sd, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iYN9cREY-r3N",
    "outputId": "0954af07-f4b9-474a-d6bf-45355f2b360d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x16022ff70>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net2NetTransformer(\n",
       "  (first_stage_model): VQModel(\n",
       "    (encoder): Encoder(\n",
       "      (conv_in): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (down): ModuleList(\n",
       "        (0): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "          (downsample): Downsample(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "          )\n",
       "        )\n",
       "        (1): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "          (downsample): Downsample(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "          )\n",
       "        )\n",
       "        (2): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (nin_shortcut): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "          (downsample): Downsample(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))\n",
       "          )\n",
       "        )\n",
       "        (3): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "          (downsample): Downsample(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))\n",
       "          )\n",
       "        )\n",
       "        (4): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (nin_shortcut): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList(\n",
       "            (0): AttnBlock(\n",
       "              (norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): AttnBlock(\n",
       "              (norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mid): Module(\n",
       "        (block_1): ResnetBlock(\n",
       "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (attn_1): AttnBlock(\n",
       "          (norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (block_2): ResnetBlock(\n",
       "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (norm_out): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "      (conv_out): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (decoder): Decoder(\n",
       "      (conv_in): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (mid): Module(\n",
       "        (block_1): ResnetBlock(\n",
       "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (attn_1): AttnBlock(\n",
       "          (norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (block_2): ResnetBlock(\n",
       "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (up): ModuleList(\n",
       "        (0): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (2): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "        )\n",
       "        (1): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (nin_shortcut): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (2): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "          (upsample): Upsample(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (2): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "          (upsample): Upsample(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (3): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (nin_shortcut): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (2): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "          (upsample): Upsample(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (4): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (2): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList(\n",
       "            (0): AttnBlock(\n",
       "              (norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): AttnBlock(\n",
       "              (norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (2): AttnBlock(\n",
       "              (norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (upsample): Upsample(\n",
       "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm_out): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "      (conv_out): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (loss): DummyLoss()\n",
       "    (quantize): VectorQuantizer2(\n",
       "      (embedding): Embedding(1024, 256)\n",
       "    )\n",
       "    (quant_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (post_quant_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (cond_stage_model): SOSProvider()\n",
       "  (permuter): Identity()\n",
       "  (transformer): GPT(\n",
       "    (tok_emb): Embedding(1024, 832)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (ln1): LayerNorm((832,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((832,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CausalSelfAttention(\n",
       "          (key): Linear(in_features=832, out_features=832, bias=True)\n",
       "          (query): Linear(in_features=832, out_features=832, bias=True)\n",
       "          (value): Linear(in_features=832, out_features=832, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (resid_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=832, out_features=832, bias=True)\n",
       "        )\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=832, out_features=3328, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3328, out_features=832, bias=True)\n",
       "          (3): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (ln1): LayerNorm((832,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((832,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CausalSelfAttention(\n",
       "          (key): Linear(in_features=832, out_features=832, bias=True)\n",
       "          (query): Linear(in_features=832, out_features=832, bias=True)\n",
       "          (value): Linear(in_features=832, out_features=832, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (resid_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=832, out_features=832, bias=True)\n",
       "        )\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=832, out_features=3328, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3328, out_features=832, bias=True)\n",
       "          (3): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (ln1): LayerNorm((832,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((832,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CausalSelfAttention(\n",
       "          (key): Linear(in_features=832, out_features=832, bias=True)\n",
       "          (query): Linear(in_features=832, out_features=832, bias=True)\n",
       "          (value): Linear(in_features=832, out_features=832, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (resid_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=832, out_features=832, bias=True)\n",
       "        )\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=832, out_features=3328, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3328, out_features=832, bias=True)\n",
       "          (3): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (ln1): LayerNorm((832,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((832,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CausalSelfAttention(\n",
       "          (key): Linear(in_features=832, out_features=832, bias=True)\n",
       "          (query): Linear(in_features=832, out_features=832, bias=True)\n",
       "          (value): Linear(in_features=832, out_features=832, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (resid_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=832, out_features=832, bias=True)\n",
       "        )\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=832, out_features=3328, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3328, out_features=832, bias=True)\n",
       "          (3): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (ln1): LayerNorm((832,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((832,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CausalSelfAttention(\n",
       "          (key): Linear(in_features=832, out_features=832, bias=True)\n",
       "          (query): Linear(in_features=832, out_features=832, bias=True)\n",
       "          (value): Linear(in_features=832, out_features=832, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (resid_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=832, out_features=832, bias=True)\n",
       "        )\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=832, out_features=3328, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3328, out_features=832, bias=True)\n",
       "          (3): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (ln1): LayerNorm((832,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((832,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CausalSelfAttention(\n",
       "          (key): Linear(in_features=832, out_features=832, bias=True)\n",
       "          (query): Linear(in_features=832, out_features=832, bias=True)\n",
       "          (value): Linear(in_features=832, out_features=832, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (resid_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=832, out_features=832, bias=True)\n",
       "        )\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=832, out_features=3328, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3328, out_features=832, bias=True)\n",
       "          (3): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (ln1): LayerNorm((832,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((832,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CausalSelfAttention(\n",
       "          (key): Linear(in_features=832, out_features=832, bias=True)\n",
       "          (query): Linear(in_features=832, out_features=832, bias=True)\n",
       "          (value): Linear(in_features=832, out_features=832, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (resid_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=832, out_features=832, bias=True)\n",
       "        )\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=832, out_features=3328, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3328, out_features=832, bias=True)\n",
       "          (3): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (ln1): LayerNorm((832,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((832,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CausalSelfAttention(\n",
       "          (key): Linear(in_features=832, out_features=832, bias=True)\n",
       "          (query): Linear(in_features=832, out_features=832, bias=True)\n",
       "          (value): Linear(in_features=832, out_features=832, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (resid_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=832, out_features=832, bias=True)\n",
       "        )\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=832, out_features=3328, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3328, out_features=832, bias=True)\n",
       "          (3): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): Block(\n",
       "        (ln1): LayerNorm((832,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((832,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CausalSelfAttention(\n",
       "          (key): Linear(in_features=832, out_features=832, bias=True)\n",
       "          (query): Linear(in_features=832, out_features=832, bias=True)\n",
       "          (value): Linear(in_features=832, out_features=832, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (resid_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=832, out_features=832, bias=True)\n",
       "        )\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=832, out_features=3328, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3328, out_features=832, bias=True)\n",
       "          (3): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): Block(\n",
       "        (ln1): LayerNorm((832,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((832,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CausalSelfAttention(\n",
       "          (key): Linear(in_features=832, out_features=832, bias=True)\n",
       "          (query): Linear(in_features=832, out_features=832, bias=True)\n",
       "          (value): Linear(in_features=832, out_features=832, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (resid_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=832, out_features=832, bias=True)\n",
       "        )\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=832, out_features=3328, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3328, out_features=832, bias=True)\n",
       "          (3): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): Block(\n",
       "        (ln1): LayerNorm((832,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((832,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CausalSelfAttention(\n",
       "          (key): Linear(in_features=832, out_features=832, bias=True)\n",
       "          (query): Linear(in_features=832, out_features=832, bias=True)\n",
       "          (value): Linear(in_features=832, out_features=832, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (resid_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=832, out_features=832, bias=True)\n",
       "        )\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=832, out_features=3328, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3328, out_features=832, bias=True)\n",
       "          (3): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): Block(\n",
       "        (ln1): LayerNorm((832,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((832,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CausalSelfAttention(\n",
       "          (key): Linear(in_features=832, out_features=832, bias=True)\n",
       "          (query): Linear(in_features=832, out_features=832, bias=True)\n",
       "          (value): Linear(in_features=832, out_features=832, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (resid_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=832, out_features=832, bias=True)\n",
       "        )\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=832, out_features=3328, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3328, out_features=832, bias=True)\n",
       "          (3): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((832,), eps=1e-05, elementwise_affine=True)\n",
       "    (head): Linear(in_features=832, out_features=1024, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set model device to cpu\n",
    "model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tTusbqk2y0u3"
   },
   "source": [
    "## Load example data\n",
    "\n",
    "Load an example segmentation and visualize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oCNy13FGPMy6"
   },
   "source": [
    "Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hNBdHGbNTrfM"
   },
   "source": [
    "Our model also employs a VQGAN for the conditioning information, i.e. the segmentation in this example. Let's autoencode the segmentation map. Encoding returns both the quantized code and its representation in terms of indices of a learned codebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pp-OsC1RXAQ9"
   },
   "source": [
    "Let's sample indices corresponding to codes from the image VQGAN given the segmentation code. We init randomly and take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 689
    },
    "id": "VTfao3jJSCfW",
    "outputId": "1a3320ff-a389-4759-ced3-5dee58bf7a29"
   },
   "outputs": [],
   "source": [
    "def show_image(s):\n",
    "  s = s.detach().cpu().numpy().transpose(0,2,3,1)[0]\n",
    "  s = ((s+1.0)*127.5).clip(0,255).astype(np.uint8)\n",
    "  s = Image.fromarray(s)\n",
    "  display(s)\n",
    "  \n",
    "codebook_size = config.model.params.first_stage_config.params.embed_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49msample(torch\u001b[39m.\u001b[39;49mrandint_like(torch\u001b[39m.\u001b[39;49mzeros(\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m), codebook_size), torch\u001b[39m.\u001b[39;49mrandint_like(torch\u001b[39m.\u001b[39;49mzeros(\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m), codebook_size), \u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/sdk/miniforge3/envs/py39/lib/python3.9/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/dev/CS4240/project/CS4240-Reproduction-Project/taming/models/cond_transformer.py:117\u001b[0m, in \u001b[0;36mNet2NetTransformer.sample\u001b[0;34m(self, x, c, steps, temperature, sample, top_k, callback)\u001b[0m\n\u001b[1;32m    115\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((c,x),dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    116\u001b[0m block_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer\u001b[39m.\u001b[39mget_block_size()\n\u001b[0;32m--> 117\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer\u001b[39m.\u001b[39mtraining\n\u001b[1;32m    118\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpkeep \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m:\n\u001b[1;32m    119\u001b[0m     \u001b[39m# one pass suffices since input is pure noise anyway\u001b[39;00m\n\u001b[1;32m    120\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(x\u001b[39m.\u001b[39mshape)\u001b[39m==\u001b[39m\u001b[39m2\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.sample(torch.randint_like(torch.zeros(1,1), codebook_size), torch.randint_like(torch.zeros(1,1), codebook_size), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ftDWneY3zJZ5"
   },
   "source": [
    "## Sample an image\n",
    "\n",
    "We use the transformer in a sliding window manner to sample all code entries sequentially. The code below assumes a window size of $16\\times 16$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 724
    },
    "id": "5rVRrUOwbEH0",
    "outputId": "f5f860e0-6a3c-44ac-9361-bd4d1be8318e"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'z_indices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mIPython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdisplay\u001b[39;00m \u001b[39mimport\u001b[39;00m clear_output\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtime\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m idx \u001b[39m=\u001b[39m z_indices\n\u001b[1;32m      5\u001b[0m idx \u001b[39m=\u001b[39m idx\u001b[39m.\u001b[39mreshape(z_code_shape[\u001b[39m0\u001b[39m],z_code_shape[\u001b[39m2\u001b[39m],z_code_shape[\u001b[39m3\u001b[39m])\n\u001b[1;32m      7\u001b[0m cidx \u001b[39m=\u001b[39m c_indices\n",
      "\u001b[0;31mNameError\u001b[0m: name 'z_indices' is not defined"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "idx = z_indices\n",
    "idx = idx.reshape(z_code_shape[0],z_code_shape[2],z_code_shape[3])\n",
    "\n",
    "cidx = c_indices\n",
    "cidx = cidx.reshape(c_code.shape[0],c_code.shape[2],c_code.shape[3])\n",
    "\n",
    "temperature = 1.0\n",
    "top_k = 100\n",
    "update_every = 50\n",
    "\n",
    "start_t = time.time()\n",
    "for i in range(0, z_code_shape[2]-0):\n",
    "  if i <= 8:\n",
    "    local_i = i\n",
    "  elif z_code_shape[2]-i < 8:\n",
    "    local_i = 16-(z_code_shape[2]-i)\n",
    "  else:\n",
    "    local_i = 8\n",
    "  for j in range(0,z_code_shape[3]-0):\n",
    "    if j <= 8:\n",
    "      local_j = j\n",
    "    elif z_code_shape[3]-j < 8:\n",
    "      local_j = 16-(z_code_shape[3]-j)\n",
    "    else:\n",
    "      local_j = 8\n",
    "\n",
    "    i_start = i-local_i\n",
    "    i_end = i_start+16\n",
    "    j_start = j-local_j\n",
    "    j_end = j_start+16\n",
    "    \n",
    "    patch = idx[:,i_start:i_end,j_start:j_end]\n",
    "    patch = patch.reshape(patch.shape[0],-1)\n",
    "    cpatch = cidx[:, i_start:i_end, j_start:j_end]\n",
    "    cpatch = cpatch.reshape(cpatch.shape[0], -1)\n",
    "    patch = torch.cat((cpatch, patch), dim=1)\n",
    "    logits,_ = model.transformer(patch[:,:-1])\n",
    "    logits = logits[:, -256:, :]\n",
    "    logits = logits.reshape(z_code_shape[0],16,16,-1)\n",
    "    logits = logits[:,local_i,local_j,:]\n",
    "\n",
    "    logits = logits/temperature\n",
    "\n",
    "    if top_k is not None:\n",
    "      logits = model.top_k_logits(logits, top_k)\n",
    "\n",
    "    probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "    idx[:,i,j] = torch.multinomial(probs, num_samples=1)\n",
    "\n",
    "    step = i*z_code_shape[3]+j\n",
    "    if step%update_every==0 or step==z_code_shape[2]*z_code_shape[3]-1:\n",
    "      x_sample = model.decode_to_img(idx, z_code_shape)\n",
    "      clear_output()\n",
    "      print(f\"Time: {time.time() - start_t} seconds\")\n",
    "      print(f\"Step: ({i},{j}) | Local: ({local_i},{local_j}) | Crop: ({i_start}:{i_end},{j_start}:{j_end})\")\n",
    "      show_image(x_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "3Pu-VjGHnFta"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "taming-transformers.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
